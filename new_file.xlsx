no Li mi â­ **Real-World ETL Pipeline Example â€“ TD Bank (ADF + Databricks)**

**â€œTell me about an ETL process you built at TD using ADF and Databricks.â€**

In my current role at TD Bank, one of the key ETL pipelines I worked on involved ingesting large volumes of operational and analytical data from on-prem SQL environments into **Azure Data Lake** and transforming it for downstream analytics teams.

### **1. Source Systems & Data Movement**

The pipeline ingested data from:

* **On-prem SQL Server**
* **Internal Cisco telephony datasets**
* **Legacy data repositories used by analytics and QA teams**

The datasets were large, frequently updated, and required consistent schemas.

### **2. Orchestration â€“ Azure Data Factory**

I used **Azure Data Factory (ADF)** to orchestrate the end-to-end workflow:

* Scheduled incremental ingestion triggers
* Used copy activities to extract from SQL systems
* Implemented parameterized pipelines so the same pipeline could ingest **multiple datasets**, improving maintainability
* Added **retry logic**, logging, and monitoring alerts to guarantee reliability in production

ADF moved the raw data into **bronze (raw) zones** in the data lake.

### **3. Transformation â€“ Azure Databricks & PySpark**

Once the data landed in the lake, **Databricks** handled transformation and quality checks:

* Used **PySpark** to clean, normalize, and merge the data
* Implemented **schema validation** to manage schema drift
* Performed **key transformations** such as:

  * flattening nested structures
  * standardizing timestamps
  * joining reference tables
  * deduplicating large datasets

In one initiative, I developed a **Data Populator Tool (Python + Databricks + Regex)** to automate ingestion preparation, reducing manual transformation time by **~25%**.

### **4. Storage â€“ Delta Lake Architecture**

Transformed data was stored in:

* **Bronze** â†’ Raw ingestion
* **Silver** â†’ Cleaned and validated data
* **Gold** â†’ Aggregated or business-ready tables

Delta capabilities like **ACID transactions, time-travel, and optimized Z-ordering** helped with query performance and traceability â€” which is critical for regulated data environments like banking.

### **5. Metadata & Governance**

I also built a **Unified Metadata Search Tool** within Databricks:

* Consolidated metadata from Delta tables, Bitbucket, GitHub, and SQL Server
* Enabled developers and analysts to discover datasets more easily
* Strengthened governance and minimized duplicated pipelines

This tool improved operational efficiency and reduced dependency on tribal knowledge.

### **6. Production Support & Monitoring**

As part of L3 support:

* Investigated ingestion failures
* Resolved schema mismatch issues
* Performed root-cause analysis for broken pipelines
* Documented fixes and updated data lineage

This experience is directly aligned with Deloitteâ€™s expectations around **data quality, troubleshooting, and surveillance data reliability**.

--------------------------



https://www1.myrbcsso.rbcinsurance.com/rbcquoter/bol/auto/bundle?lang=en&key=WUVmTVk5QTNjYkxwVEREdlBhb3I4cytGQm9UYUd0ZTYvb3hZZ3B1Zm1kRk1uMS9ETExIMWhPUUd4emZRSzlYc0dIdVJJRDBTblgvaVlqK2prTnN2UEpwUkxlaWN2d3JBNXdGNmdsVjJOVjFJTXhpMFYxTmVjTDloUTJLd25oNldwYWZEeU5MTnUzd1Bzc2FmT050THBFSXZSWHlHZndvbXhwUzNXUVpNSUtBPQ

Introduction & Goal of the Session

Hey everyone, thanks for being here.

So today I want to talk about a problem we often face when weâ€™re looking for table schemas across different places like Bitbucket, DBFS, Azure SQL, or our Delta tables in SRZ. The current process is slow and manual â€” we usually have to open different tools, search by eye, pull data into CSV files, compare them, and even then, sometimes we canâ€™t find what weâ€™re looking for. It takes time and can get frustrating.

Thatâ€™s why I started thinking: what if we build a tool that can help us with this? The idea is, we give it part of a table name or column name, and it automatically searches across all the data sources we care about, and gives us a list of matches. It should save us a lot of time and manual work.

In this session, Iâ€™ll show you the basic idea, a diagram of how it works, and how we can use it.

The only challenge I see for now is access â€” especially when connecting from a Databricks notebook to something like SQL Server. There might be firewalls, tokens, or authentication needed, so weâ€™ll probably need support from other teams like Matthewâ€™s team to get that sorted out. And if not, we can think of other ways to .





Based on your attached images â€” your feature sheet, the prework Excel, and the workshop invitation â€” here is a strong and structured response to the question:

â¸»

Why these projects are meaningful and pivotal to me

These projects represent critical milestones in my professional journey across both TD and the Middle East region. Each one reflects a combination of problem-solving, technical innovation, and leadership.

â¸»

ğŸ”¹ 1. Unified Metadata Search Tool

Why itâ€™s meaningful:
This tool addresses a core challenge in any large data ecosystem: locating schema, table names, and relationships efficiently.
Message:
I want to highlight my ability to transform pain points into tools that improve collaboration, onboarding, and productivity across teams. This project shows how innovation can begin from a conversation and turn into a tangible solution.

â¸»

ğŸ”¹ 2. IDC Populator (Data Populator Tool)

Why itâ€™s meaningful:
By leveraging Databricks, Python, and Pandas, I automated a time-consuming ingestion process, reducing delays by 30%.
Message:
This project demonstrates how technical depth can create real-time performance gains at scale, with direct value to the business and platform stability.

â¸»

ğŸ”¹ 3. API Ingestion Migration Project

Why itâ€™s meaningful:
This project automated ingestion from sources like Salesforce and third-party APIs, replacing time-consuming manual work.
Message:
It reflects my passion for automation, pattern recognition, and designing reusable ingestion frameworks in a scalable way.

â¸»

ğŸ”¹ 4. ERP Development â€“ Supply Chain

Why itâ€™s meaningful:
I designed a full ERP system covering sales, accounting, inventory, routing, and more. This was one of the most complex end-to-end systems Iâ€™ve led.
Message:
This shows my ability to build foundational business systems that improve efficiency and support long-term growth. It highlights both technical architecture and strategic thinking.

â¸»

ğŸ”¹ 5. Established IT Department

Why itâ€™s meaningful:
Built a team from scratch, implemented infrastructure, and developed SOPs. It was a leadership challenge and growth experience.
Message:
This shows my people management skills, department setup, and the ability to deliver systems while building a team culture.

â¸»

ğŸ”¹ 6. ERP Implementation

Why itâ€™s meaningful:
Executed a massive rollout â€” from infrastructure to training â€” over multiple branches.
Message:
I want to highlight my project execution experience, large-scale rollout planning, and cross-functional coordination.

â¸»

ğŸ”¹ 7. SQL OLTP Design + BI

Why itâ€™s meaningful:
I designed an OLTP structure integrated with BI, providing performance and reporting improvements.
Message:
It reflects my deep understanding of data modeling, reporting, and supporting business insights through the right backend structure.

â¸»

ğŸ”¹ 8. Data Warehouse + BI

Why itâ€™s meaningful:
Created a central DW using SSIS and reporting layers for business visibility.
Message:
Demonstrates my expertise in ETL, DW design, and report delivery, especially using Microsoft technologies like SSIS/SSRS.

â¸»

ğŸ”¹ 9. Ordering Mobile App Designer + DB

Why itâ€™s meaningful:
I led development of a mobile ordering app integrated with the backend for retail and restaurant clients.
Message:
This showcases full-stack thinking and an ability to create intuitive customer-facing solutions driven by backend design.

â¸»

ğŸ”¹ 10. GIS Tracking for Sales/Distributors

Why itâ€™s meaningful:
Developed a system to track distributor locations and route optimization.
Message:
This is where I began connecting data with real-world logistics, leading into my passion for AI in route optimization and spatial analytics.

â¸»

Subject: Thank You for Todayâ€™s Discussion

Hi [Name],

Thank you again for taking the time to speak with me today. I really enjoyed our conversation and learning more about the Data Scientist III role supporting Finance AI2.

I also wanted to mention that I bring direct finance-related experience from my previous ERP project, where I designed core financial modules such as the general ledger, sales, inventory, and financing systems. This background, combined with my technical expertise in big data, ingestion pipelines, Databricks, Python, SQL, and my current work in data analysis within the Data Science team, gives me a strong foundation to support Finance partners effectively.

Iâ€™m very excited about the opportunity to contribute to Finance AI2 and help drive insights, automation, and strong collaboration across the Finance organization.

Thank you again, and please let me know if you need any additional information from me.

Best regards,
Ali



====###########

Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ + Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ù¾Ø±ÙˆÙ…ÙˆØ´Ù†ØŒ Ø­Ù‚ÙˆÙ‚ Ùˆ L10 (Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)

Hi [Manager Name],
I really appreciate you taking the time to meet. Before anything, I want to say something openly â€” since I joined the team, Iâ€™ve always heard that youâ€™re supportive, straightforward, and someone who genuinely looks out for your people. Iâ€™ve personally felt that, and thatâ€™s why Iâ€™m comfortable having this honest conversation.

Since the day I joined the team, there have been ongoing conversations almost every month about layoffs and restructuring.
And weâ€™ve seen strong technical people around us get affected.
With the more recent changes â€” like offshore resources joining and responsibilities shifting â€” it naturally creates uncertainty.

So I wanted to ask from your perspective:
How do you see these changes impacting our team and our long-term direction?

(Ù…Ú©Ø« â€” Ø¨Ø°Ø§Ø± Ú©Ø§Ù…Ù„ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡)

â¸»

ğŸŸ¦ Ù…Ø±Ø­Ù„Ù‡ Ø¯ÙˆÙ…: Ø¨Ø­Ø« ØªÚ©Ù†ÛŒÚ©Ø§Ù„

The second thing I wanted to discuss is the future of the work in our team.
Since I joined, most of my responsibilities have been support-oriented. Iâ€™m trying to grow technically â€” especially in AI, ML, and engineering work â€” so I wanted to understand if there will be opportunities for more technical or development-focused projects on our team.

(Ù…Ú©Ø« Ú©Ù† â€” Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø®ÙˆØ¯Ø´ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø§Ù…Ú©Ø§Ù†Ø§Øª ØªÛŒÙ… Ø­Ø±Ù Ø²Ø¯Ù†)

â¸»

ğŸŸ§ Ù…Ø±Ø­Ù„Ù‡ Ø³ÙˆÙ…: Ø§ÛŒÙ†Ø¬Ø§ L10 Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø­Ù‚ÙˆÙ‚ Ø±Ø§ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ

Depending on that direction, I also wanted to talk about my own growth path.
Iâ€™ve been working hard since I joined, and I feel that with my background and experience, I can contribute at a higher level if the opportunity exists.

So I wanted to ask you honestly:
Do you see a path for me to grow to the next level â€” potentially L10 â€” or receive a compensation adjustment if I take on more technical or higher-impact work?

Iâ€™m not asking for anything immediately; I just want to understand whether thatâ€™s a realistic direction within our team.

(Ø§ÛŒÙ† Ø¬Ù…Ù„Ù‡ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒÙ‡: Ù†Ù‡ ÙØ´Ø§Ø± Ù…ÛŒØ§Ø±Ù‡ØŒ Ù†Ù‡ Ù…Ø·Ø§Ù„Ø¨Ù‡ Ø§Ø³Øª â†’ ÙÙ‚Ø· â€œÙ…Ø³ÛŒØ±â€ Ù…ÛŒâ€ŒÙ¾Ø±Ø³ÛŒ)

â¸»

ğŸŸ¥ Ù…Ø±Ø­Ù„Ù‡ Ú†Ù‡Ø§Ø±Ù…: Ø§Ú¯Ø± Ù…Ø³ÛŒØ± Ù†Ø¨ÙˆØ¯ â†’ Ù†Ù‚Ø´ ML Ø±Ø§ Ù…Ø·Ø±Ø­ Ú©Ù†

If our team isnâ€™t moving toward more technical work or if growth to the next level isnâ€™t possible in the near future, then I want to be transparent with you.

Iâ€™ve seen an internal role that aligns very closely with my technical background, especially in ML.
I havenâ€™t applied yet â€” because I wanted to talk to you first, out of respect.

If I decide to explore it, would you be open to supporting me?
And I want to make sure that doing so wonâ€™t negatively affect my position here if things donâ€™t work out.


----------------------------Yamin Brian-------------------------------------------
Ø¯Ø± Ø¬Ù„Ø³Ù‡ Ø§Ù…Ø±ÙˆØ² Ø§ÛŒÙ†ØªØ±ÙˆÛŒÙˆ Ø¯Ø± Ø®ØµÙˆØµ ØªÛŒÙ… Ù„ÛŒØ° ØŒ Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø±Ø§ Ø§Ø² Ù…Ù† Ø³ÙˆØ§Ù„ Ú©Ø±Ø¯Ù† ØŸ ÛŒØ¹Ù†ÛŒ Ú†ÛŒ Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ ØŸ 
What your previous managers say about you , What about opportunities? What would they say, where some of your opportunities, things you could learn are things you could do better? 

so for example, I'm just going I don't know if this is you, you know, it sounds like you're someone who likes to do very thorough work. â€©Has your manager ever said that sometimes you're solutions are too complicated, for example, and that you could try to work faster versus, you know, I don't know if that's you, right? But something like that as there in your performance reviews or in your coaching with your managers, 
as something come up that you know as an opportunity for you and that you could work on? Yes, absolutely. 
	#answer 
As a technical lead, I sometimes took on too much myself early on, 
especially for complex problems. My manager coached me on delegating 
earlier and trusting the team more.

Since then, Iâ€™ve been more intentional 
about breaking problems down, assigning ownership, 
and focusing my time on unblockÂ­ing the team rather than solving everything personally.

Sorry, I may not have fully understood the question at firstâ€”possibly due to some interview nervesâ€”but Iâ€™m very open to feedback and I regularly ask my manager in quarterly reviews to highlight areas where I can improve.
One example was a few years ago around visibility of my work: Iâ€™m not naturally someone who self-promotes and tend to be more reserved, and my manager coached me on communicating my contributions more clearly, which Iâ€™ve been actively working on.

Ù†Ø³Ø®Ù‡ Ø®ÛŒÙ„ÛŒ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„â€ŒØªØ± Ùˆ safeâ€ŒØªØ± (Ø§Ú¯Ù‡ Ø®ÙˆØ§Ø³ØªÛŒ):

Iâ€™m very open to feedback, and in my quarterly reviews I actively ask my manager to be direct about areas where I can improve so I can work on them.
One example was around visibility of my workâ€”since Iâ€™m naturally more reserved and focused on delivery rather than self-promotion, my manager coached me to communicate progress and impact more 
proactively, which Iâ€™ve been consciously improving as part of 
my leadership 

yamin  
you were talking with a team about how to validate the quality of the data and someone who recommended a sport check you didn't necessarily agree, you thought being better to check comprehensively, but you also understand that there would be a large number of records maybe in a table in your case it may be very simple. maybe 25, maybe 200, maybe even 2000. But in other cases, there could be two million, right? â€©Or 20 million, right? Or in the billions, right? Now, something like that, what maybe just a very simple way, right? â€©Like how would you check with source and target the matching records for a table that has a large volume of transactions? What would be an approach you would be used, thinking technically from a technical standpoint.

For large-volume tables, I wouldnâ€™t do row-by-row validation because itâ€™s not scalable.
I usually combine multiple lightweight checks: record counts by partition or business key, aggregate comparisons like sums and min/max on key columns, and targeted sampling for deeper validation.

If needed, I also use hash-based checks at a grouped level to detect discrepancies without scanning every row, and only drill down when an anomaly is detected.


Yamin 2nd Quest
My question to you is in a setting like that, right, what are some key principles? And again, not necessarily a writer or wrong answer here, but I just want to understand your deduction in thinking. Would you say our maybe the tricks of the trade or maybe things that are fundamental for a team to stay organized, move forward, and deliver at a rapid speed? â€©What are some critical elements that are needed for a team to function that well from your standpoint or from your opinion?


For a team to move fast and stay organized, I think three things are fundamental: clear expectations, pragmatic decision-making, and ownership.
When standards are clear and people understand when to go simple versus when to go deep, the team avoids 
unnecessary complexity and can deliver quickly and consistently.

contd 
So this is more from a leadership point of view, right? So we have a team, we need to move forward. We need to stay organized, and I my question to you is, from your standpoint, what are some fundamental things and they don't have to be necessarily technical, they could be functional. â€©What are some of those critical things that are important for the team to stay focussed, stay organize March forward and deliver quality things at a obviously in a record time or in a very fast-paced environment. What are some of those fundamental things? this is not a technical question, right? 

Like, Leveraging teams to get a hold of somebody versus sending them an email, for example, right? So that you can move quickly, right? Do you have examples of how you organize yourself, how you lead, how you take ownership, that you can show the team so that we can move quickly? 

In situations like that, my first step is to understand whatâ€™s slowing them downâ€”whether itâ€™s priority conflicts, unclear requirements, or a technical blocker.
If timelines are tight, I take ownership by helping directly, breaking the work into smaller steps, or pairing with them to unblock progress, rather than waiting or escalating immediately.
The goal is to support and coach in the moment so the sprint stays on track and the person also learns how to move faster next time.



======
path = "abfss://home@edaaaazepca0edanacc0001.dfs.core.windows.net/users/EDC/"

prefix = "ADIDO-5612-athena_validation_endc1-"
suffix = ".csv"

files = dbutils.fs.ls(path)

matched_files = [
    f for f in files
    if f.name.startswith(prefix) and f.name.endswith(suffix)
]

if not matched_files:
    raise Exception("No matching files found")





from operator import attrgetter

latest_file = sorted(
    matched_files,
    key=attrgetter("modificationTime"),
    reverse=True
)[0]

latest_file.path
